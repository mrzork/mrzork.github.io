---
title: "Applying learning machines on information from sensors of quantified self movement"
author: "CHerrera"
date: "Fri Jul 25 13:51:18 2014"
output: html_document
---

## Practical Machine Learning
### Peer Assessments
#### Prediction Assignment Writeup

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively.

In this analysis was use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

the method presented below even attempt to predict how the participants made the exercise.

The procedure performed was the following: 

* the necessary libraries are loaded
```{r}
library(caret)
library("randomForest")
```

* data is read
```{r cache=TRUE}
pml.training <- read.csv("C:/Documents and Settings/cherrera/Escritorio/Datos proyecto maquinas/pml-training.csv")
pml.testing <- read.csv("C:/Documents and Settings/cherrera/Escritorio/Datos proyecto maquinas/pml-testing.csv")
```

* a selection of information na include variables that have a significant amount of data __"NA"__, then only cases that have the information on all variables are selected is done.

```{r cache=TRUE}
include<-(names(pml.training[(colSums(is.na(pml.training))/19622)<0.5]))
pml.inc<-subset(pml.training,select=include)
pml.training<-pml.inc[complete.cases(pml.inc),]
```

* perform a selection of all the variables that have the following characteristics: they are numerical and do not represent a factor does'nt superfluous information, such as time information, nor are abstract variables of the data captured by the sensors, ie they use only information delivered by the sensors clean.

```{r cache=TRUE}
rm(include,pml.inc)
l<-0
for(i in 1:93){
    if(is.numeric(pml.training[[i]])==TRUE){l[i]<-names(pml.training[i])}
    if(is.numeric(pml.training[[i]])==FALSE){l[i]<-"NO"}
}
sel<-l[l!="NO"]
pml.training2<-subset(pml.training,select=sel)
pml.testing2<-subset(pml.testing,select=sel)
rm(sel,l,i)
pml.training2<-pml.training2[,-c(1:4)]
pml.testing2<-pml.testing2[,-c(1:4)]
```

* pre process the data to find few major components are required to capture 99% of the variability in the data

```{r cache=TRUE}
a<-preProcess(pml.training2,method="pca",thresh = 0.99);a

```
* According to the above components 36 is required to capture 99% of the variability in the data. 

* thereafter a principal component model is generated with 36 components and seek his representation for both the training data to the test data.
```{r cache=TRUE}
PsubPred<-preProcess(pml.training2,method = "pca",pcaComp = 36)
trainpc<-predict(PsubPred,pml.training2)
testingpc<-predict(PsubPred,pml.testing2)
PsubPred2<-data.frame(classe=pml.training[,93],trainpc)
```

* generate a model of randomforest, the training data generated by the principal components.
```{r cache=TRUE}
mod1<-randomForest(classe~.,data=PsubPred2)
```

* evaluate the training data relative to the prediction generated by the model previously generated.
```{r cache=TRUE}
confusionMatrix(PsubPred2$classe,predict(mod1,trainpc))
```

* according to the above model classification generated predicted in full details, so we proceed to the prediction of the test data in search of the prediction for each __problem_id__ this hoping that all predictions are correct according to that seen with their performance in the training data.

```{r cache=TRUE}
predict(mod1,testingpc)
```
**according to validator Prediction Assignment Submission, he fulfilled the expected target prediction.**

#### __End.__
